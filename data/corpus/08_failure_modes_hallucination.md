# Common Failure Mode: Hallucination

Hallucination happens when a model produces confident but unsupported claims. RAG can reduce hallucination when retrieval is relevant and prompts enforce grounded answers.

Evaluation should include unanswerable questions to verify the model refuses instead of fabricating details.

